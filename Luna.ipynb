{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 40,
>>>>>>> 33acf72 (hoy)
=======
   "execution_count": 2,
>>>>>>> 6673177 (V0.1)
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import TextVectorization"
=======
    "import tensorflow as tf"
>>>>>>> 33acf72 (hoy)
=======
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import TextVectorization"
>>>>>>> 6673177 (V0.1)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39m'\u001b[39;49m\u001b[39m..///The-Luna-AI-Project/1M-GPT4-Augmented.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m,inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msystem_prompt\u001b[39m\u001b[39m'\u001b[39m,inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:509\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m     use_nullable_dtypes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    507\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 509\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39;49mread(\n\u001b[0;32m    510\u001b[0m     path,\n\u001b[0;32m    511\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m    512\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    513\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[0;32m    514\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m    515\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    516\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:230\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, use_nullable_dtypes, dtype_backend, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     pa_table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mparquet\u001b[39m.\u001b[39mread_table(\n\u001b[0;32m    228\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39mcolumns, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     result \u001b[39m=\u001b[39m pa_table\u001b[39m.\u001b[39;49mto_pandas(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mto_pandas_kwargs)\n\u001b[0;32m    232\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    233\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m_as_manager(\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\array.pxi:837\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\table.pxi:4114\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\pandas_compat.py:820\u001b[0m, in \u001b[0;36mtable_to_blockmanager\u001b[1;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[0;32m    818\u001b[0m _check_data_column_metadata_consistency(all_columns)\n\u001b[0;32m    819\u001b[0m columns \u001b[39m=\u001b[39m _deserialize_column_index(table, all_columns, column_indexes)\n\u001b[1;32m--> 820\u001b[0m blocks \u001b[39m=\u001b[39m _table_to_blocks(options, table, categories, ext_columns_dtypes)\n\u001b[0;32m    822\u001b[0m axes \u001b[39m=\u001b[39m [columns, index]\n\u001b[0;32m    823\u001b[0m \u001b[39mreturn\u001b[39;00m BlockManager(blocks, axes)\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\pandas_compat.py:1168\u001b[0m, in \u001b[0;36m_table_to_blocks\u001b[1;34m(options, block_table, categories, extension_columns)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_table_to_blocks\u001b[39m(options, block_table, categories, extension_columns):\n\u001b[0;32m   1164\u001b[0m     \u001b[39m# Part of table_to_blockmanager\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m \n\u001b[0;32m   1166\u001b[0m     \u001b[39m# Convert an arrow table to Block from the internal pandas API\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m     columns \u001b[39m=\u001b[39m block_table\u001b[39m.\u001b[39mcolumn_names\n\u001b[1;32m-> 1168\u001b[0m     result \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49mtable_to_blocks(options, block_table, categories,\n\u001b[0;32m   1169\u001b[0m                                     \u001b[39mlist\u001b[39;49m(extension_columns\u001b[39m.\u001b[39;49mkeys()))\n\u001b[0;32m   1170\u001b[0m     \u001b[39mreturn\u001b[39;00m [_reconstruct_block(item, columns, extension_columns)\n\u001b[0;32m   1171\u001b[0m             \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m result]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
=======
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
>>>>>>> 33acf72 (hoy)
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39m'\u001b[39;49m\u001b[39m..///The-Luna-AI-Project/1M-GPT4-Augmented.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m,inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msystem_prompt\u001b[39m\u001b[39m'\u001b[39m,inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:509\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m     use_nullable_dtypes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    507\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 509\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39;49mread(\n\u001b[0;32m    510\u001b[0m     path,\n\u001b[0;32m    511\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m    512\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    513\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[0;32m    514\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m    515\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    516\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:230\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, use_nullable_dtypes, dtype_backend, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     pa_table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mparquet\u001b[39m.\u001b[39mread_table(\n\u001b[0;32m    228\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39mcolumns, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     result \u001b[39m=\u001b[39m pa_table\u001b[39m.\u001b[39;49mto_pandas(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mto_pandas_kwargs)\n\u001b[0;32m    232\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    233\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m_as_manager(\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\array.pxi:837\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\table.pxi:4114\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\pandas_compat.py:820\u001b[0m, in \u001b[0;36mtable_to_blockmanager\u001b[1;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[0;32m    818\u001b[0m _check_data_column_metadata_consistency(all_columns)\n\u001b[0;32m    819\u001b[0m columns \u001b[39m=\u001b[39m _deserialize_column_index(table, all_columns, column_indexes)\n\u001b[1;32m--> 820\u001b[0m blocks \u001b[39m=\u001b[39m _table_to_blocks(options, table, categories, ext_columns_dtypes)\n\u001b[0;32m    822\u001b[0m axes \u001b[39m=\u001b[39m [columns, index]\n\u001b[0;32m    823\u001b[0m \u001b[39mreturn\u001b[39;00m BlockManager(blocks, axes)\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\pandas_compat.py:1168\u001b[0m, in \u001b[0;36m_table_to_blocks\u001b[1;34m(options, block_table, categories, extension_columns)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_table_to_blocks\u001b[39m(options, block_table, categories, extension_columns):\n\u001b[0;32m   1164\u001b[0m     \u001b[39m# Part of table_to_blockmanager\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m \n\u001b[0;32m   1166\u001b[0m     \u001b[39m# Convert an arrow table to Block from the internal pandas API\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m     columns \u001b[39m=\u001b[39m block_table\u001b[39m.\u001b[39mcolumn_names\n\u001b[1;32m-> 1168\u001b[0m     result \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49mtable_to_blocks(options, block_table, categories,\n\u001b[0;32m   1169\u001b[0m                                     \u001b[39mlist\u001b[39;49m(extension_columns\u001b[39m.\u001b[39;49mkeys()))\n\u001b[0;32m   1170\u001b[0m     \u001b[39mreturn\u001b[39;00m [_reconstruct_block(item, columns, extension_columns)\n\u001b[0;32m   1171\u001b[0m             \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m result]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
>>>>>>> 6673177 (V0.1)
   "source": [
    "df=pd.read_parquet('..///The-Luna-AI-Project/1M-GPT4-Augmented.parquet')\n",
    "df.drop(columns='id',inplace=True)\n",
    "df.drop(columns='system_prompt',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 42,
>>>>>>> 33acf72 (hoy)
=======
   "execution_count": null,
>>>>>>> 6673177 (V0.1)
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You will be given a definition of a task first...</td>\n",
       "      <td>[   [\"AFC Ajax (amateurs)\", \"has ground\", \"Spo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generate an approximately fifteen-word sentenc...</td>\n",
       "      <td>Midsummer House is a moderately priced Chinese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What happens next in this paragraph?  She then...</td>\n",
       "      <td>C. She then dips the needle in ink and using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Please answer the following question: I want t...</td>\n",
       "      <td>Based on the passage, discuss the primary moti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James runs a TV show and there are 5 main char...</td>\n",
       "      <td>James pays the minor characters $15,000 each e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 6673177 (V0.1)
       "                                            question                                           response\n",
       "0  You will be given a definition of a task first...  [   [\"AFC Ajax (amateurs)\", \"has ground\", \"Spo...\n",
       "1  Generate an approximately fifteen-word sentenc...  Midsummer House is a moderately priced Chinese...\n",
       "2  What happens next in this paragraph?  She then...  C. She then dips the needle in ink and using t...\n",
       "3  Please answer the following question: I want t...  Based on the passage, discuss the primary moti...\n",
       "4  James runs a TV show and there are 5 main char...  James pays the minor characters $15,000 each e..."
<<<<<<< HEAD
      ]
     },
     "execution_count": 13,
=======
       "                                            question   \n",
       "0  You will be given a definition of a task first...  \\\n",
       "1  Generate an approximately fifteen-word sentenc...   \n",
       "2  What happens next in this paragraph?  She then...   \n",
       "3  Please answer the following question: I want t...   \n",
       "4  James runs a TV show and there are 5 main char...   \n",
       "\n",
       "                                            response  \n",
       "0  [   [\"AFC Ajax (amateurs)\", \"has ground\", \"Spo...  \n",
       "1  Midsummer House is a moderately priced Chinese...  \n",
       "2  C. She then dips the needle in ink and using t...  \n",
       "3  Based on the passage, discuss the primary moti...  \n",
       "4  James pays the minor characters $15,000 each e...  "
      ]
     },
     "execution_count": 42,
>>>>>>> 33acf72 (hoy)
=======
      ]
     },
     "execution_count": 13,
>>>>>>> 6673177 (V0.1)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.replace('\\n',' ',regex=True)\n",
    "df.head()"
   ]
  },
  {
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 6673177 (V0.1)
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------- Testing stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test-splitting first"
   ]
  },
  {
<<<<<<< HEAD
=======
>>>>>>> 33acf72 (hoy)
=======
>>>>>>> 6673177 (V0.1)
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 6673177 (V0.1)
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(df['question'],df['response'],train_size=0.7,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-head attention. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, d_model):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        \n",
    "    def call(self, q, k, v, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.split_heads(self.wq(q), batch_size)\n",
    "        k = self.split_heads(self.wk(k), batch_size)\n",
    "        v = self.split_heads(self.wv(v), batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "        \n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer=tf.keras.layers.TextVectorization(\n",
    "    split='whitespace',\n",
    "    standardize=None,\n",
    "    output_mode='int',\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'text_vectorization_1' (type TextVectorization).\n\n{{function_node __wrapped__RaggedTensorToTensor_num_row_partition_tensors_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[696427,6454] and type int64 on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:RaggedTensorToTensor]\n\nCall arguments received by layer 'text_vectorization_1' (type TextVectorization):\n  • inputs=113093    Please answer the following question: Has a do...\n122614    How is \"The United States has also been reluct...\n522906    Brammertz ile görüşmesi sonrasında Belgrad mer...\n928687    1. At the age of nine , he appeared in his fir...\n355487    If \"A man in a blue sweatshirt and black cap h...\n                                ...                        \n963395    @KHill215 Let's go with 'not so much'   How wo...\n117952    Ingram Micro is all set to acquire Tech Pacifi...\n435829    This article: Mickey Rubin, a Coney Island lif...\n305711    Premise: A young girl works on homework at a t...\n985772    Creating a self portrait is not your typical s...\nName: question, Length: 696427, dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Transform the training data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train_vectorized \u001b[39m=\u001b[39m vectorize_layer(X_train)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Print the first few examples to check\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\devix\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'text_vectorization_1' (type TextVectorization).\n\n{{function_node __wrapped__RaggedTensorToTensor_num_row_partition_tensors_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[696427,6454] and type int64 on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:RaggedTensorToTensor]\n\nCall arguments received by layer 'text_vectorization_1' (type TextVectorization):\n  • inputs=113093    Please answer the following question: Has a do...\n122614    How is \"The United States has also been reluct...\n522906    Brammertz ile görüşmesi sonrasında Belgrad mer...\n928687    1. At the age of nine , he appeared in his fir...\n355487    If \"A man in a blue sweatshirt and black cap h...\n                                ...                        \n963395    @KHill215 Let's go with 'not so much'   How wo...\n117952    Ingram Micro is all set to acquire Tech Pacifi...\n435829    This article: Mickey Rubin, a Coney Island lif...\n305711    Premise: A young girl works on homework at a t...\n985772    Creating a self portrait is not your typical s...\nName: question, Length: 696427, dtype: object"
     ]
    }
   ],
   "source": [
    "# Transform the training data\n",
    "X_train_vectorized = vectorize_layer(X_train)\n",
    "\n",
    "# Print the first few examples to check\n",
    "for i in range(5):\n",
    "    print(\"Original text:\", X_train.iloc[i])\n",
    "    print(\"Vectorized sequence:\", X_train_vectorized[i])\n",
    "    print()"
   ]
<<<<<<< HEAD
=======
   "source": []
>>>>>>> 33acf72 (hoy)
=======
>>>>>>> 6673177 (V0.1)
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
